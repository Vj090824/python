{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae84f8-9ba8-44ba-9881-7c14d9ac5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos\n",
    "Q1. Write a python program to extract the video URL of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "Ans:\n",
    "    A Python code snippet that you can use to extract video URLs from a YouTube channel\n",
    "    page using the `BeautifulSoup` library and the `requests` library.\n",
    "    You'll need to install these libraries if you haven't already.\n",
    "\n",
    "Here's a Python program to extract the video URLs of the first five videos from a YouTube channel page:\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all the video links on the page\n",
    "video_links = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "first_five_video_urls = []\n",
    "for link in video_links[:5]:\n",
    "    video_url = 'https://www.youtube.com' + link['href']\n",
    "    first_five_video_urls.append(video_url)\n",
    "\n",
    "# Print the extracted video URLs\n",
    "for i, video_url in enumerate(first_five_video_urls, start=1):\n",
    "    print(f\"Video {i}: {video_url}\")\n",
    "\n",
    "Make sure you have the `requests` and `beautifulsoup4` libraries installed in\n",
    "your Python environment. You can install them using pip:\n",
    "\n",
    "pip install requests beautifulsoup4\n",
    "\n",
    "\n",
    "This code will scrape the video URLs from the given YouTube channel page and print \n",
    "the URLs of the first five videos. Please note that web scraping may be subject to terms of \n",
    "service on websites, so make sure you have the right to scrape the content you are interested in.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans:\n",
    "    \n",
    "Python code snippet using the BeautifulSoup and requests libraries to scrape the video thumbnail\n",
    "URLs from a YouTube channel page if you have the HTML content of the page. You would need to fetch\n",
    "the HTML content from the provided URL using the `requests` library and\n",
    "then parse it with BeautifulSoup.\n",
    "\n",
    "Here's a sample Python program to extract the thumbnail URLs of the first five\n",
    "videos from a YouTube channel page:\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace this with the actual URL you want to scrape\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Find the thumbnail elements for the first five videos\n",
    "    thumbnail_elements = soup.find_all(\"img\", class_=\"style-scope yt-img-shadow\")\n",
    "    \n",
    "    # Extract the thumbnail URLs\n",
    "    thumbnail_urls = [element[\"src\"] for element in thumbnail_elements[:5]]\n",
    "    \n",
    "    # Print the thumbnail URLs\n",
    "    for i, thumbnail_url in enumerate(thumbnail_urls, start=1):\n",
    "        print(f\"Thumbnail URL for video {i}: {thumbnail_url}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "Make sure you have the `requests` and `beautifulsoup4` libraries installed.\n",
    "You can install them using pip:\n",
    "\n",
    "\n",
    "pip install requests beautifulsoup4\n",
    "\n",
    "\n",
    "Remember that web scraping might violate the terms of service of some websites,\n",
    "so make sure you have the necessary permissions and adhere to the\n",
    "website's policies when scraping content.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q3. Write a python program to extract the title of the first five videos.\n",
    "\n",
    "\n",
    "Ans:\n",
    "    \n",
    "A Python code s that demonstrates how to extract the titles of the first five videos from a \n",
    "YouTube channel using the `requests` library and the `BeautifulSoup` library for web scraping.\n",
    "Please note that web scraping may be subject to website terms of service, \n",
    "and you should ensure you have the necessary permissions to access and scrape \n",
    "the content from the website.\n",
    "\n",
    "First, make sure you have the `requests` and `beautifulsoup4` libraries installed.\n",
    "You can install them using pip if you haven't already:\n",
    "\n",
    "\n",
    "pip install requests beautifulsoup4\n",
    "\n",
    "\n",
    "Here's a Python program to extract the titles of the first five videos from a YouTube channel:\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the YouTube channel's videos page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all video titles on the page\n",
    "        video_titles = soup.find_all('a', {'id': 'video-title'})\n",
    "\n",
    "        # Extract the titles of the first five videos\n",
    "        for i, video_title in enumerate(video_titles[:5]):\n",
    "            print(f\"Video {i+1}: {video_title.text.strip()}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "This code will print the titles of the first five videos on the specified YouTube channel's videos page.\n",
    "Please replace the `url` variable with the actual URL of the YouTube channel you want to scrape.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q4. Write a python program to extract the number of views of the first five videos.\n",
    "\n",
    "\n",
    "Ans:\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "Python code  using web scraping libraries like BeautifulSoup and requests to scrape the number of views\n",
    "from the first five videos on a YouTube channel page. Please note that web scraping might be subject to\n",
    "terms of service on websites, and you should ensure you have permission to scrape the content.\n",
    "\n",
    "Here's an example of how you can scrape the number of views from the first five videos \n",
    "on a YouTube channel page:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all video elements on the page\n",
    "video_elements = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "    # Iterate through the first five video elements and extract the view count\n",
    "    for video in video_elements[:5]:\n",
    "        # Extract the view count text\n",
    "    view_count_text = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text.strip()\n",
    "\n",
    "        # Print the view count\n",
    "        print(\"View Count:\", view_count_text)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "\n",
    "Make sure you have installed the `requests` and `beautifulsoup4` libraries using pip:\n",
    "\n",
    "\n",
    "pip install requests beautifulsoup4\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans:\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "use to extract the time of posting of videos from a YouTube channel if\n",
    "you have access to the video data.\n",
    "\n",
    "To extract the time of posting of videos, you would typically need to use a YouTube API\n",
    "or a web scraping library like BeautifulSoup and requests to fetch the necessary information \n",
    "from the YouTube channel's page. Here's a general Python script to demonstrate how you \n",
    "can extract the time of posting of videos using BeautifulSoup and requests:\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the channel's videos page\n",
    "response = requests.get(channel_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all video elements on the page\n",
    "    video_elements = soup.find_all('a', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "    # Extract the time of posting for the first five videos\n",
    "    for i, video in enumerate(video_elements[:5]):\n",
    "        video_title = video.get('title')\n",
    "        video_time = video.find('div', {'id': 'metadata-line'}).find_all('span')[0].get_text()\n",
    "        print(f\"Video {i + 1}: {video_title}\")\n",
    "        print(f\"Time of posting: {video_time}\")\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "\n",
    "\n",
    "Make sure you have the BeautifulSoup and requests libraries installed before\n",
    "running the script. You can install them using pip:\n",
    "\n",
    "\n",
    "pip install beautifulsoup4 requests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
